<!DOCTYPE html>
<html>
  <head>
    <title>Inference for SLR</title>
    <meta charset="utf-8">
    <meta name="author" content="Dr. Maria Tackett" />
    <link rel="stylesheet" href="sta210-slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Inference for SLR
### Dr. Maria Tackett
### 01.23.19

---




## Announcements 

- Lab 01 due **today at 11:59p**

- HW 01 due Mon, Jan 28 at 11:59p


---

class: middle, center

## Questions from Lab 01? 


---

## Agenda

- Recap: Simple linear regression basics

- `\(R^2\)`

- **Review:** Inference for the mean, `\(\mu\)`

- Inference for the slope, `\(\beta_1\)`

---

## Packages and Data



```r
library(tidyverse)
library(broom)
library(modelr)
library(fivethirtyeight)
```


```r
movie_scores &lt;- fandango %&gt;%
  rename(tomatometer = rottentomatoes, audience = rottentomatoes_user)
```

---

## rottentomatoes.com

Can ratings from movie critics be used to predict the ratings from movie goers?

--

&lt;img src="img/03/movie-rating-2.png" width="70%" style="display: block; margin: auto;" /&gt;

--

&lt;img src="img/03/movie-rating-1.png" width="70%" style="display: block; margin: auto;" /&gt;

---

## Critic vs. Audience Ratings

- To answer this question, we will analyze the critic and audience scores from rottentomatoes.com.  
    - The data was first used in the article [Be Suspicious of Online Movie Ratings, Especially Fandango's](https://fivethirtyeight.com/features/fandango-movies-ratings/).

- Variables: 
    - `tomatometer`: Rotten Tomatoes Tomatometer score for the film (0 - 100)
    - `audience`: Rotten Tomatoes user score for the film (0 - 100)

---

class: middle, center

## Recap: SLR Basics

---

## Regression Model 

`$$Y|X \sim N(\beta_0 + \beta_1 X,\sigma^2)$$`

&lt;img src="img/03/regression.png" width="80%" style="display: block; margin: auto;" /&gt;

- `\(\sigma\)`: the standard deviation of `\(Y\)` as a function of `\(X\)` 

- **Assumption:** `\(\sigma\)` is equal for all values of `\(X\)`

---

## Regression Model

.alert[
`$$\color{blue}{Y|X \sim N(\beta_0 + \beta_1 X,\sigma^2)}$$`
]

--

- For a single observation `\((x_i, y_i)\)`

`$$\color{blue}{y_i = \beta_0 + \beta_1 x_i + \epsilon_i \hspace{10mm} \epsilon_i \sim N(0,\sigma^2)}$$`

--

- We want to use the `\(n\)` observations `\((x_1,y_1), \ldots, (x_n, y_n)\)` to estimate `\(\beta_0\)` and `\(\beta_1\)`. We will use *least-squares regression* estimates.

---

## Scatterplot 

&lt;img src="03-slr-inference_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---

## Simple Linear Regression Model


```r
model &lt;- lm(audience ~ tomatometer, data=movie_scores)
tidy(model)
```

```
## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   32.3      2.34        13.8 4.03e-28
## 2 tomatometer    0.519    0.0345      15.0 2.70e-31
```

- **Slope**: For every one percentage increase in the Tomatometer score, we expect the audience score to increase by 0.519%. 

- **Intercept**: If the Tomatometer score is 0%, we expect the audience score to be about 32.316%.

---

## Assumptions for Regression 

1. &lt;font class="vocab"&gt;Linearity: &lt;/font&gt;The plot of the mean value for `\(y\)` against `\(x\)` falls on a straight line

2. &lt;font class="vocab"&gt;Constant Variance: &lt;/font&gt;The regression variance is the same for all values of `\(x\)`

3. &lt;font class="vocab"&gt;Normality: &lt;/font&gt; For a given `\(x\)`, the distribution of `\(y\)` around its mean is Normal

4. &lt;font class="vocab"&gt;Independence: &lt;/font&gt;All observations are independent

---

## Linearity &amp; Constant variance



&lt;img src="03-slr-inference_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;

- From the scatterplot and plot of the residuas vs. predictor, we conclude the **linearity** assumption is sufficiently met.

- From the plot of the residuals vs. predictor, we conclude the **constant variance** assumption is sufficiently met. 

---

## Normality of residuals 
&lt;img src="03-slr-inference_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;

- From the histogram and QQ-plot, we conclude that the **Normality** assumption is met.

---

## Independence

- If we assume critics and audiences judge each movie independently, then we could conclude that the independence assumption is reasonably met. 

- There potentially could be a cluster effect due to movie genre, so a good next step would be to analyze the residuals by genre. 

--

- Due to time constraints, let's assume the independence assumption is reasonably met for the class notes.

---

class: middle, center

## Assessing Model Fit

---

## Estimating `\(\sigma^2\)`

- Residual Standard Error

---

## `\(R^2\)`

We can use the coefficient of determination, `\(R^2\)`, to measure how well the model fits the data 

- `\(R^2\)` is the proportion of variation in `\(Y\)` that is explained by the regression line (reported as percentage)

- It is difficult to determinely what exactly is a "good" value of `\(R^2\)`. It depends on the context of the data.

---

## Calculating `\(R^2\)`

.instructions[
`$$R^2 = \frac{\text{TSS} - \text{RSS}}{\text{TSS}} = 1 - \frac{\text{RSS}}{\text{TSS}}$$`
]

- &lt;font class="vocab"&gt;Total Sum of Squares: &lt;/font&gt;Total variation in the `\(Y\)`'s before fitting the regression 

`$$\text{TSS}= \sum\limits_{i=1}^{n}(y_i - \bar{y})^2 = (n-1)s^2_y$$`

- &lt;font class="vocab"&gt;Residual Sum of Squares (RSS): &lt;/font&gt;Total variation in the `\(Y\)`'s around the regression line (sum of squared residuals)
`$$\text{RSS} = \sum\limits_{i=1}^{n}[y_i - (\hat{\beta}_0 + \hat{\beta}_1x_i)]^2$$`

---

## Rotten Tomatoes Data


```r
rsquare(model,movie_scores)
```

```
## [1] 0.6106479
```

The Tomatometer score explains about 61.06% of the variation in audience scores on rottentomatoes.com.

---

class: middle, center

## Inference for `\(\beta_1\)`

---

## Questions of interest

In our example, we will treat the data as a random sample of movies from rottentomatoes.com

**Questions of interest**
- What is a plausible range of values of the true population slope for `tomatometer`?
- Is there truly a linear relationship between the tomatometer and audience scores? In other words, is there enough evidence to conclude that the true population slope is different from 0?

---

## Statistical Inference

- &lt;font class="vocab"&gt;Confidence Interval: &lt;/font&gt; Estimate a range of plausible values for a parameter

- &lt;font class="vocab"&gt;Hypothesis Test: &lt;/font&gt; Test a specified claim or hypothesis about the parameter

- In this class, our focus will be on inference for regression coefficients, i.e. the `\(\beta_j\)`'s

---


## Questions of interest

- What is a plausible range of values of the true population slope for `tomatometer`? (&lt;font class="vocab"&gt;Confidence Interval&lt;/font&gt;)

- Is there truly a linear relationship between the tomatometer and audience scores? In other words, is there enough evidence to conclude that the true population slope is different from 0? (&lt;font class="vocab"&gt;Hypothesis Test&lt;/font&gt;)

---

## Distribution of `\(\beta_1\)`


---

class: middle, center

**What is a plausible range of values of the true population slope for `tomatometer`?**

---

## Confidence Intervals

- Developed by Jerzy Neyman (1930s)

- **What**: Estimates a population parameter using a sample statistic
    - Assuming sample data is a simple random sample
  
- **Why**: Because the statistic is a random variable, its value is subject to chance error
    - We want a range of plausible values for the population parameter that takes the chance error into account

- We assume the data is from a random sample that is representative of the population. A confidence interval will not make up for systematic bias in the data


---

### Interpreting the 95% Confidence Interval

.center[
&lt;img src="img/03/confidence_intervals.png" width="40%" style="display: block; margin: auto;" /&gt;
]
- It's a procedure to produce an interval for the parameter of interest
- If we take many samples of size `\(n\)`, the intervals caluclated from the sample will contain the parameter about 95% of the time
- It is **not** interpreted as the probability the parameter of interest is in a given interval

---

## General form of the CI

- Let &lt;font class="vocab"&gt;SE&lt;/font&gt; be the standard error of the statistic used to estimate the parameter of interest, then the general form of the confidence interval is

.alert[
`$$\text{ Estimate} \pm \text{ (critical value) } \times \text{SE}$$`
]
- *Note*: The critical value is determined by the distribution of the estimate (statistic) and the confidence level

- For the regression slope: 
    - `\(\hat{\beta}_1\)` is the statistic used to estimate the parameter, `\(\beta_1\)` 
    - We will write the confidence interval as 
    `$$\mathbf{\hat{\beta}_1 \pm t^* SE(\hat{\beta}_1)}$$`
    
---

## Confidence interval for `\(\beta_1\)`

- The confidence interval for the regression slope is 

.alert[
`$$\mathbf{\color{blue}{\hat{\beta}_1 \pm t^* SE(\hat{\beta}_1)}}$$`
]

- `\(t^*\)` is the critical value associated with the confidence level.
  + It is calculated from a `\(t\)` distribution with `\(n-2\)` degrees of freedom
  
- `\(SE(\hat{\beta}_1)\)` is the standard error for the slope 

`$$SE(\hat{\beta}_1) = \sqrt{\frac{\hat{\sigma}^2}{\sum\limits_{i=1}^n (x_i - \bar{x})^2}} \hspace{2.5mm} = \hspace{2.5mm} \hat{\sigma}\sqrt{\frac{1}{(n-1)s_X^2}}$$`

---

## t-distribution vs. Normal 

- Since we calculate `\(SE(\hat{\beta}_1)\)` using `\(\hat{\sigma}\)`, an estimate of `\(\sigma\)`, we will use the *t* distribution to find the critical value for the confidence interval.

- The critical value `\(t^*\)` is calculated from the *t(n-2)* distribution - the *t* distribution with *n-2* degrees of freedom.

&lt;img src="img/03/tdistribution.png" width="50%" style="display: block; margin: auto;" /&gt;

&lt;font size="2"&gt;Picture from &lt;i&gt;The Basic Practice of Statistics (7th edition)&lt;/i&gt;&lt;/font&gt;


---

### Application: Confidence Interval for `\(\mu\)`


```r
library(tidyverse)
library(WRS2) #has the Pygmalion data
iq_scores &lt;- Pygmalion
glimpse(iq_scores)
```

```
## Observations: 114
## Variables: 3
## $ Pretest  &lt;dbl&gt; 49, 58, 17, 18, 80, 101, 90, 66, 72, 67, 111, 82, 114, …
## $ Posttest &lt;dbl&gt; 90, 107, 110, 122, 105, 128, 120, 77, 94, 113, 208, 90,…
## $ Group    &lt;fct&gt; treatment, treatment, treatment, treatment, treatment, …
```

---

### Application: Confidence Interval for `\(\mu\)`



```r
# update this 
# ggplot(data = iq_scores, mapping = aes(x = Pretest)) +geom_histogram()
```

---

### Application: Confidence Interval for `\(\mu\)`

**UPDATE** 

```r
#iq_scores %&gt;% summarise(n=n(), mean=mean(Pretest), 
                       # median = median(Pretest), s=sd(Pretest))
```


```r
#(t.crit &lt;- qt(0.975,113))
```

1. Calculate a 95% confidence interval for the mean IQ score of elementary students at the beginning of the school year. 
2. Interpret the interval in the context of the problem.



---

### Application: Confidence Interval for `\(\mu\)`

- Similarly, we can calculate a 95% confidence interval for the mean IQ scores of elementary school students at the end of the school year.


```r
t.test(iq_scores$Posttest, conf.level = 0.95)$conf.int
```

```
## [1]  96.85908 107.68478
## attr(,"conf.level")
## [1] 0.95
```

- Compare the intervals for the pretest and post-test. **Is there evidence that the students' IQ scores were higher, on average, at the end of the school year?**

---

## Hypthesis Tests

Question being answered: 

- Given the data in our sample, is there evidence &lt;u&gt;**against**&lt;/u&gt; a specified hypothesis about the parameter of interest?

- In other words:
  + Are the data consistent with the specified hypothesis?
  
---

## Outline of a Hypothesis Test

- Assume some hypothesis about a parameter is true
    - This hypothesis is the &lt;font class="vocab3"&gt;null hypothesis&lt;/font&gt;

- Identify the appropriate statistic based on the distribution of the parameter of interest.
    - This statistic is the &lt;font class="vocab3"&gt;test statistic.&lt;/font&gt;
    - The statistic should take an extreme value when the hypothesis is false.

- Use the data in your sample to calculate the value of the test statistic.

---

## Outline of a Hypothesis Test

- Calculate the probability of observing a value of the statistic that is as extreme or more extreme than the observed value, under the assumed hypothesis.
    - This calculated probability is the &lt;font class="vocab3"&gt;p-value&lt;/font&gt;.

- Assess the p-value. A small p-value means...
    a.The assumed hypothesis is incorrect
    b. The assumed hypothesis is correct and a rare event has occurred

---

## Outline of a Hypothesis Test
 
- State a conclusion about the hypothesis based on the assessment of the p-value.
    - Since event (b) is by definition rare, we will conclude a &lt;font color="green"&gt;small p-value&lt;/font&gt; indicates that there &lt;font color="green"&gt;is sufficient evidence&lt;/font&gt; to claim &lt;font color="green"&gt;that the assumed hypothesis is false&lt;/font&gt;.
    
    - When the p-value is &lt;font color="red"&gt;not small&lt;/font&gt;, we will conclude that there &lt;font color="red"&gt;is not sufficient evidence&lt;/font&gt; to claim the assumed hypothesis is false.

---

## Conducting a Hypothesis Test 

1. State the hypotheses

2. Calculate the relevant test statistic

3. Calculate the p-value

4. State the conclusion in the context of the problem

---

## Formulating Hypotheses

- &lt;font class="vocab3"&gt;Null Hypothesis&lt;/font&gt;, `\(\color{blue}{H_0}\)`: statement about the population parameter that is believed to be true or is used to put forth an argument unless it can be shown to be incorrect 

- &lt;font class="vocab3"&gt;Alternative Hypothesis&lt;/font&gt;, `\(\color{blue}{H_a}\)`:  claim about the parameter that contradicts the null hypothesis 
  + This is typically what we want to show

- `\(H_a\)` can be one-sided or two-sided
  + This will determine how we calculate the p-value

---

## Test Statistic

- Test statistics take the following general form: 

$$ \frac{\text{estimate} - \text{hypothesized value}}{SE}$$


- &lt;font class="vocab"&gt;Interpretation: &lt;/font&gt; How many standard errors the estimate is from the hypothesized value
    - The sign of the test statistic indicates if the estimate is above or below the hypothesized value

---

### Can you define "p-value"?

- [Scientists Define *p*-value](https://fivethirtyeight.abcnews.go.com/video/embed/56150342)

- [Statisticians Found One Thing They Can Agree On: It's Time to Stop Misusing P-Values](https://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/)

---

## Calculating the p-value

- &lt;font class="vocab3"&gt;p-value:&lt;/font&gt; probability of getting a test statistic as extreme or more extreme than the calculated test statistic, assuming the null hypothesis is true

- When the alternative has a `\(&gt;\)`, the p-value is calculated using the area to the right of the test statistic

- When the alternative has a `\(&lt;\)`, the p-value is calculated using the area to the left of the test statistic

- When the alternative has `\(\neq\)`, the p-value is calculated as the area to the left of `\(-|\text{test statistic}|\)` and to the right of `\(|\text{test statistic}|\)`

---


### What the *p-value* is and is not

**What the p-value is NOT**:
- It is &lt;u&gt;&lt;b&gt;not&lt;/b&gt;&lt;/u&gt; the probability the null hypothesis is true
  + The null hypothesis is either true or not true
- (1 - *p-value*) is &lt;u&gt;&lt;b&gt;not&lt;/b&gt;&lt;/u&gt; the probability that the alternative hypothesis is true
  + The alternative hypothesis is either true or not true
  
.alert[
**What the p-value &lt;u&gt;IS&lt;/u&gt;**

The probability of getting a test statistic as extreme or more extreme than the calculated test statistic, *assuming the null hypothesis is true*
]

---

## Interpreting the p-value

|  Magnitude of p-value |             Interpretation            |
|:---------------------:|:-------------------------------------:|
| p-value &lt; 0.01        | strong evidence against `\(H_0\)`         |
| 0.01 &lt; p-value &lt; 0.05 | moderate evidence against `\(H_0\)`       |
| 0.05 &lt; p-value &lt; 0.1  | weak evidence against `\(H_0\)`           |
| p-value &gt; 0.1         | effectively no evidence against `\(H_0\)` |
&lt;br&gt; 
&lt;br&gt;

**Note:** These are general guidelines. The strength of evidence depends on the context of the problem.

---

## Statistical Significance

- A threshold can be used to decide whether or not to reject `\(H_0\)`. 

- This threshold is called the &lt;font class="vocab3"&gt;significance level&lt;/font&gt; and is usually denoted by `\(\alpha\)`

- When `\(H_0\)` is rejected, we use the term &lt;font class="vocab3"&gt; statistically significant &lt;/font&gt; to describe the outcome of the test.

- *Example*: When `\(\alpha = 0.05\)`, results are statistically significance when the p-value is `\(&lt; 0.05\)`

---

## Statistical Significance

- Do not rely strictly on the significance level to make a conclusion!
--

- Suppose the significance level is 0.05
--

  + If the p-value is 0.05001, we do not reject `\(H_0\)`
--

  + If the p-value is 0.04999, we do reject `\(H_0\)`
--

- 0.05001 and 0.04999 are practically the same, yet they led to different conclusions. 
--

- Always state the p-value when reporting results and assess their magnitude in the context of your problem. 

---

### Not Statistically Significant

- An outcome of failing to reject `\(H_0\)` is &lt;u&gt;not&lt;/u&gt; a failed study/experiment

- Obtaining an outcome of "no significant effect" or "no significant difference" is still valid 

- It is often just as important to learn that the `\(H_0\)` can't be refuted

---

## Type I &amp;  Type II Errors

&lt;img src="img/03/errors.png" width="80%" style="display: block; margin: auto;" /&gt;
.small[
Image: *The Basic Practice of Statistics (7th Ed.)*
]

- &lt;font class="vocab3"&gt;Type I Error&lt;/font&gt;: Reject `\(H_0\)` when `\(H_0\)` is true
- &lt;font class="vocab3"&gt;Type II Error&lt;/font&gt;: Fail to reject `\(H_0\)` when `\(H_1\)` is true
- Replicate study when possible to reduce these errors

---

## Sample Size

- Probability of Type I error is not affected by the sample size
  + What affects the probability of Type I error?
--

- Probability of Type II error decreases as the sample size increases
--

- If the hypothesized value is not very different from actual parameter value, you need a large sample size
--

- When designing a study, it is good practice to conduct a power analyses to determine the sample size required to minimize the chance of Type II error

---

class: regular 

## Sample Size

- It is always preferable to collect as much data as possible (as long as it is accurate and relevant)
--

- A test can reject almost any false `\(H_0\)`, i.e. detect even very small effects, when the sample size is large enough
--

- *Note*: Statistical significance is &lt;u&gt;not&lt;/u&gt; the same as practical significance 
  + Even if `\(H_0\)` is rejected, the detected effect may be too small to be of any practical use

---

class: middle, center

## Inference for for `\(\beta_1\)`

---

## Slope: Confidence Interval

- The confidence interval for the regression slope is 

`$$\mathbf{\color{blue}{\hat{\beta}_1 \pm t^* SE(\hat{\beta}_1)}}$$`

--

- `\(t^*\)` is the critical value associated with our confidence level. 
  + It is calculated from a `\(t\)` distribution with `\(n-2\)` degrees of freedom


--

- `\(SE(\hat{\beta}_1)\)` is the standard error for the slope 

`$$SE(\hat{\beta}_1) = \hat{\sigma}\sqrt{\frac{1}{(n-1)s_X^2}}$$`

---

## rottomatoes.com


```
## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   32.3      2.34        13.8 4.03e-28
## 2 tomatometer    0.519    0.0345      15.0 2.70e-31
```

Calculate a 95% confidence interval to estimate the true slope of `tomatometer`

---

## rottentomatoes.com

- **UPDATE THIS SLIDE*

&lt;!--
`$$0.0475366 \pm 1.652586 \times 0.0026906 = \mathbf{(0.04309, 0.05198)}$$`
&lt;br&gt;

**Interpretation:** We are 90% confident that the population regression slope is between (0.04309, 0.05198). This means, for each additional $1000 spent on TV advertising, we expect the mean increase in sales to be between approximately $43090 and $51980.
--&gt;

---

### Confidence Interval in R


```r
confint_tidy(model,conf.level=0.9)
```

```
## # A tibble: 2 x 2
##   conf.low conf.high
##      &lt;dbl&gt;     &lt;dbl&gt;
## 1   28.4      36.2  
## 2    0.462     0.576
```

---

## Slope: Hypothesis Test 

- We are often interested in testing whether there is a significant linear relationship between the explanatory and response variable 

- If there is no linear relationship between the two variables, the population regression slope should equal 0 
--

- We can test the hypotheses: 

`$$\begin{aligned}&amp;\mathbf{H_0: \boldsymbol{\beta_1} = 0}\\&amp;\mathbf{H_a: \boldsymbol{\beta_1} \neq 0}\end{aligned}$$`

- This is the test conducted by the `lm()` function in R


---

## Slope: Hypothesis Test

`$$\begin{aligned}&amp;\mathbf{H_0: \boldsymbol{\beta_1} = 0}\\&amp;\mathbf{H_a: \boldsymbol{\beta_1} \neq 0}\end{aligned}$$`

- &lt;font class="vocab"&gt;Test Statistic: &lt;/font&gt; 
`$$\mathbf{\text{test statistic} = \frac{\text{Estimate} - \text{Hypothesized}}{SE} = \frac{\hat{\boldsymbol{\beta}}_1 - 0}{SE(\hat{\beta}_1)}}$$`

--


- &lt;font class="vocab"&gt;p-value:&lt;/font&gt; Calculated from a `\(t\)` distribution with `\(n-2\)` degrees of freedom
`$$\mathbf{\text{p-value} = P(t \geq |\text{test statistic}|)}$$`

---

## rottentomatoes.com


```r
tidy(model)
```

```
## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   32.3      2.34        13.8 4.03e-28
## 2 tomatometer    0.519    0.0345      15.0 2.70e-31
```

**UPDATE THE CALCULATIONS**

- &lt;font class="vocab"&gt;Hypotheses: &lt;/font&gt; `\(H_0: \beta_1 = 0 \text{ vs. }H_a: \beta_1 \neq 0\)`
--

- &lt;font class="vocab"&gt;Test Statistic: &lt;/font&gt; `\(\frac{0.0475366 - 0}{0.0026906} = 17.668\)`
--

- &lt;font class="vocab"&gt;p-value: &lt;/font&gt; `\(2\times P(t &gt; |17.668|)\)` 

```r
2*(1-pt(17.668,198)) #df  200-2 = 198 
```

```
## [1] 0
```

---

## Slope: One-sided Hypothesis Test

- You can use the test statistic from the `lm()` model output to calculate the p-value for a one-sided test 


- Suppose you want to test the hypotheses: 
`$$\begin{aligned}&amp;H_0: \beta_1 = 0\\
&amp;H_a: \beta_1 &gt; 0\end{aligned}$$`

**UPDATE**
- For the regression model of TV Advertising and Sales, we can calculate the p-value as 
`$$\text{p-value}= P(t &gt; 17.668)$$`

```r
1-pt(17.668,198) #df  200-2 = 198 
```

```
## [1] 0
```

---

class: middle, center

## Predictions for New Observations

---

class: regular

### Predictions

- We can use the regression model to predict for a response at `\(X_0\)`

`$$\text{Pred}\{Y|X_0\} = \hat{\mu}\{Y|X_0\} = \hat{\beta}_0 + \hat{\beta}_1 X_0$$`
&lt;br&gt; 

- In other words, we have the same estimate whether we want to predict the mean response at `\(X_0\)` or an individual response at `\(X_0\)`.


---

## rottentomatoes.com

**UPDATE THE CALCULATIONS**

`$$\mathbf{\hat{\mu}\{\text{sales}|\text{tv_spend}\} =  7.033 +	0.0475 \times \text{tv_spend}}$$`
- Calculate the predicted sales if the company spend $50,000 on TV advertising
  + Remember the units! 


--

- `$$\text{Pred}\{\text{sales}|\text{tv_spend}=50000\} = 7.033 + 0.0475 \times 50 = \mathbf{\color{blue}{9.408}}$$`

--

- If the company spends $50,000 in TV advertising, based on our model, they are expected to earn $9.408 million in total sales.


---

## SE for Predictions

- There is uncertainty in our predictions, so we need to calculate an SE to capture the uncertainty

- The SE is different depending on whether you are predicting an average value or an individual value

- SE is larger when predicting for an individual value than for an average value 
    - **UPDATE WHERE TO FIND FORMULAS**
    
---

## rottentomatoes.com

**UPDATE**

We wish to calculated predicted values for sales when TV spending is $50,000 , $100,000 and $150,000

--

First we will predict the &lt;font class="vocab"&gt;average&lt;/font&gt; sales

```r
# x0 = data.frame(tv_spend=c(50,100,150))
# predict.lm(model,x0,interval="confidence",conf.level=0.9)
```
&lt;br&gt; 

--

Based on our regression model, we are 90% confident that if $50,000 is spent on TV advertising, the average sales will be between $8.722 million and $10.1 million. 


---

## rottentomatoes.com

Next, we will predict the &lt;font class="vocab"&gt;individual&lt;/font&gt; sales when TV spending is $50,000, $100,000 and $150,000

```r
#x0 = data.frame(tv_spend=c(50,100,150))
#predict.lm(model,x0,interval="prediction",conf.level=0.9)
```

--

Based on our regression model, we are 90% confident that if $50,000 is spent on TV advertising, the sales in an indiviudal market will be between $2.947 million and $15.872 million.

---

## Before next class 

- Lab 01 due **today at 11:59p**

- Start Reading 03 - due Wed Jan 30
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
