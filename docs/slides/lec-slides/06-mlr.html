<!DOCTYPE html>
<html>
  <head>
    <title>Multiple Linear Regression</title>
    <meta charset="utf-8">
    <meta name="author" content="Dr. Maria Tackett" />
    <link rel="stylesheet" href="sta210-slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Multiple Linear Regression
### Dr. Maria Tackett
### 02.04.19

---






## Announcements

- Reading 04 due Wed, Feb 13

- Lab 02 due Wed, Feb 13 

- HW 02 due Mon, Feb 11 (posted after class)


---

 
## R Packages used in the notes


```r
library(tidyverse)
library(knitr)
library(broom)
library(Sleuth3) # case 1202 dataset
library(cowplot) # use plot_grid function
```

---

## Motivating Example

- In the 1970s Harris Trust and Savings Bank was sued for discrimination on the basis of sex. 

- The defense presented an analysis of the salaries for skilled, entry-level clerical employees as evidence. 

- **Question**: Did female employees receive lower starting salaries on average than male employees with similar experience and qualifications?

---

 

## Data




```r
glimpse(wages)
```

```
## Observations: 93
## Variables: 6
## $ Bsal   &lt;int&gt; 5040, 6300, 6000, 6000, 6000, 6840, 8100, 6000, 6000, 690…
## $ Senior &lt;int&gt; 96, 82, 67, 97, 66, 92, 66, 82, 88, 75, 89, 91, 66, 86, 9…
## $ Age    &lt;int&gt; 329, 357, 315, 354, 351, 374, 369, 363, 555, 416, 481, 33…
## $ Educ   &lt;int&gt; 15, 15, 15, 12, 12, 15, 16, 12, 12, 15, 12, 15, 15, 15, 1…
## $ Exper  &lt;dbl&gt; 14.0, 72.0, 35.5, 24.0, 56.0, 41.5, 54.5, 32.0, 252.0, 13…
## $ Female &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, …
```

---

## Variables

**Explanatory**
- &lt;font class="vocab"&gt;`Educ`: &lt;/font&gt;years of education
- &lt;font class="vocab"&gt;`Exper`: &lt;/font&gt;months of previous work experience (before hire at bank)
- &lt;font class="vocab"&gt;`Female`: &lt;/font&gt;1 if female, 0 if male
- &lt;font class="vocab"&gt;`Senior`: &lt;/font&gt;months worked at bank since hire
- &lt;font class="vocab"&gt;`Age`: &lt;/font&gt;age in months

**Response**
- &lt;font class="vocab"&gt;`Bsal`: &lt;/font&gt;annual salary at time of hire

---

## Salary comparison

- &lt;font class="vocab"&gt;Question: &lt;/font&gt; Did female employees receive lower starting salaries on average than male employees with similar experience and qualifications?


```r
ggplot(data=wages,aes(x=Bsal,fill=Female)) + 
  geom_density(alpha=0.5) + 
  labs(y="Starting Salary", title ="Starting Salary",
       subtitle = "by Gender") 
```

&lt;img src="06-mlr_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---

### Using ANOVA

`$$\begin{aligned}&amp;H_0: \mu_F = \mu_M\\
&amp;H_a: \mu_F \neq \mu_M\end{aligned}$$`


|term      | df|    sumsq|     meansq| statistic| p.value|
|:---------|--:|--------:|----------:|---------:|-------:|
|Female    |  1| 14045183| 14045183.2|    39.597|       0|
|Residuals | 91| 32278107|   354704.5|        NA|      NA|

.question[
- What's your conclusion?

- What is a disadvantage to using this method to answer the question?
]

---

## Salary vs. Other Variables


```r
pairs(Bsal ~ Senior + Age + Educ + Exper, data=wages)
```

&lt;img src="06-mlr_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;

---

## Multiple Regression Model

- We will calculate a multiple linear regression model with the following form: 
&lt;br&gt; 

`$$\color{blue}{Bsal = \\ 
\beta_0 + \beta_1 \text{Senior} + \beta_2 \text{Age} + \beta_3 \text{Educ} + \beta_4 \text{Exper} + \beta_5 \text{Female}}$$`
&lt;br&gt; 


- Similar to simple linear regression, this model assumes that at each combination of the predictor variables, the values `Bsal` follow a Normal distribution

---

## Regression Model

- Recall: The simple linear regression model assumes 

`$$y|x\sim N(\beta_0 + \beta_1 x, \sigma^2)$$`
--

- Similarly: The multiple linear regression model assumes 

`$$\color{blue}{y|x_1, x_2, \ldots, x_p \sim N(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p, \sigma^2)}$$`
--

- For a given observation `\((x_{i1}, x_{i2} \ldots, x_{iP}, y_i)\)`, we can rewrite the previous statement as 

`$$\color{blue}{y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \dots + \beta_p x_{ip} + \epsilon_{i} \hspace{5mm} \epsilon_i \sim N(0,\sigma^2)}$$`

---

## Regression Model 

- At any combination of `\(x's\)`, the true mean value of `\(y\)` is
`$$\color{blue}{y = \beta_0 + \beta_1 x_{1} + \beta_2 x_2 + \dots + \beta_p x_p}$$`
--

- We will use multiple linear regression to calculate an estimate of the model 
`$$\color{blue}{\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x_{1} + \hat{\beta}_2 x_2 + \dots + \hat{\beta}_p x_{p}}$$`

---

## Regression Output


```r
model &lt;- lm(Bsal ~ Senior + Age + Educ + Exper + Female, data=wages)
kable(tidy(model),format="html",digits=3)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6277.893 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 652.271 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.625 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Senior &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -22.582 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.296 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -4.264 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.631 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.721 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.876 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.384 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Educ &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 92.306 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 24.864 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.713 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Exper &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.501 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.055 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.474 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.636 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Female1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -767.913 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 128.970 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -5.954 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
---

## Interpreting `\(\hat{\beta}_j\)`

- An estimated coefficient `\(\hat{\beta}_j\)` is the amount `\(y\)` is expected to change when `\(x_j\)` increases by one unit **holding the values all other explanatory variables constant**

--

- *Example:* The estimated coefficient for `Educ` is 92.31. This means for each additional year of education an employee has, we expect starting salary to increase by about $92.31, holding all over variables constant.

---

### Hypothesis Tests for `\(\hat{\beta}_j\)`

- We want to test whether a particular coefficient has a value of 0 in the population, given all other variables in the model: 

`$$\begin{aligned}&amp;H_0: \beta_j = 0 \\ &amp;H_a: \beta_j \neq 0\end{aligned}$$`

- The test statistic reported in R is the following: 

`$$\color{blue}{\text{test statistic} = \frac{\hat{\beta}_j - 0}{SE(\hat{\beta}_j)}}$$`

---

### Hypothesis Tests for `\(\hat{\beta}_j\)`

- Suppose we want to test the following hypothesis 
`$$H_0: \beta_j = \beta_{j0}$$`

- The test statistic will take the usual form: 

`$$\color{blue}{\text{test statistic} = \frac{\hat{\beta}_j - \beta_{j0}}{SE(\hat{\beta}_j)}}$$`


- We calculate the **p-value:** using a `\(t\)` distribution with `\((n - p - 1)\)` degrees of freedom 
    - Note: There are `\((p+1)\)` total terms in the model 
  
---

## Salary 

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6277.893 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 652.271 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.625 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Senior &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -22.582 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.296 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -4.264 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.631 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.721 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.876 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.384 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Educ &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 92.306 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 24.864 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.713 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Exper &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.501 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.055 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.474 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.636 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Female1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -767.913 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 128.970 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -5.954 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

.question[
Given the other variables in the model, are the following significant predictors of `Bsal`? 

- Education (`educ`)
- Experience (`exper`)
]

---

## Salary

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6277.893 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 652.271 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.625 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Senior &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -22.582 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.296 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -4.264 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.631 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.721 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.876 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.384 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Educ &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 92.306 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 24.864 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.713 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Exper &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.501 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.055 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.474 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.636 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Female1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -767.913 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 128.970 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -5.954 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

.question[
Given the other variables in the model, which variable has a stronger linear relationship with `Bsal`? 

`Senior` or `Educ`?
]

---

### Confidence Interval for `\(\beta_j\)`

- We calculate the confidence interval in the usual way 

`$$\text{estimate} \pm t^* \times SE$$`
--

- Therefore, the confidence interval for `\(\beta_j\)` is 
`$$\color{blue}{\hat{\beta}_j \pm t^* SE(\hat{\beta}_j)}$$`

- We calculate `\(t^*\)` using a `\(t\)` distribution with `\((n - p - 1)\)` degrees of freedom

---

### CI for `Educ`

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; conf.low &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; conf.high &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6277.893 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 652.271 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.625 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4981.434 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7574.353 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Senior &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -22.582 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.296 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -4.264 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -33.108 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -12.056 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.631 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.721 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.876 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.384 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.801 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.063 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Educ &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 92.306 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 24.864 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.713 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 42.887 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 141.725 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Exper &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.501 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.055 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.474 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.636 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.597 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.598 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Female1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -767.913 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 128.970 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -5.954 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1024.255 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -511.571 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

### Notes about CI and Hypothesis Tests

- If the sample size is large enough, the test will probably reject `\(H_0: \beta_j=0\)`
  + Consider the &lt;font class="vocab"&gt;practical significance&lt;/font&gt; of the result not just the statistical significance 
 
  
--

- If the sample size is small, there may not be enough evidence to reject `\(H_0: \beta_j=0\)`
    - When you fail to reject the null hypothesis, **DON'T** immediately conclude that the variable has no association with the response. 
    - There may be a linear association that is just not strong enough to detect given your data, or there may be a non-linear association.
    

---

## Prediction

- We calculate predictions the same as with simple linear regression 

- **Example:** Suppose we want to predict the starting wages for a female who is 28 years old with 12 years of education, 11 months seniority and 2 years of prior experience. 

`$$\begin{aligned}\hat{bsal} = &amp; 6277.893 - 22.582 \times \text{Senior} + 0.631 \times \text{Age} \\ &amp;+ 92.306 \times \text{Educ} + 0.501 \times \text{Exper} - 767.913 \times \text{Female}\end{aligned}$$` 

--


```r
6277.893 - 22.582 * 11 + 0.631 * 28 + 92.306 * 12 + 0.501 * 24 - 767.913 * 1
```

```
## [1] 6398.942
```

---

## Prediction

- Just like with simple linear regression, we can use the &lt;font class="vocab"&gt;`predict.lm()`&lt;/font&gt; function in R to calculate the appropriate intervals for our predicted values 


--

- Suppose we want to predict the starting wages for a female who is 28 years old with 12 years of education, 11 months seniority and 2 years of prior experience. 

--


```r
x0 = data.frame(Senior= 11, Age = 28, Educ = 12, Exper = 24, Female = "1")
predict.lm(model,x0,interval="prediction")
```

```
##       fit      lwr      upr
## 1 6398.93 4967.054 7830.805
```

---

## Prediction

Suppose we want to predict the mean age for the subset of all females who are 28 years old with 12 years of education, 11 months of seniority and 2 years of prior experience. 

.question[
- How will the predicted value change?

- How will the interval change? 
]

--

```r
x0 = data.frame(Senior= 11, Age = 28, Educ = 12, Exper = 24, Female = "1")
*predict.lm(model,x0,interval="confidence")
```

```
##       fit      lwr      upr
## 1 6398.93 5383.844 7414.016
```

---

## Cautions

- &lt;font class="vocab3"&gt;Do not extrapolate!&lt;/font&gt; Because there are multiple explanatory variables, you can extrapolation in many ways

--

- The multiple regression model only shows &lt;font class="vocab3"&gt; association, not causality &lt;/font&gt;
  + To prove causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study 

---

class: middle, center

## Assumptions 

---

## Assumptions 

The confidence intervals and hypothesis tests are reliable only when the regression assumptions are reasonably satisfied

1. &lt;font class="vocab"&gt;Linearity: &lt;/font&gt; Response variable has a linear relationship with the explanatory variables in the model

2. &lt;font class="vocab"&gt;Constant Variance: &lt;/font&gt;The regression variance is the same for all set of predictor variables `\((x_1, \ldots, x_p)\)`

3. &lt;font class="vocab"&gt;Normality: &lt;/font&gt; For a given `\((x_1, \ldots, x_p)\)`, the distribution of `\(y\)` around its mean is Normal

4. &lt;font class="vocab"&gt;Independence: &lt;/font&gt;All observations are independent

---

## Scatterplots 

- Look at a scatterplot of the response variable vs. each of the predictor variables in the exploratory data analysis before calculating the regression model 

- This is a good way to check for obvious departures from linearity 
    - Could be an indication that a higher order term or transformation is needed (will discuss this next class)

---

## Residual Plots

- **Plot the residuals vs. the predicted values**
    - Can expose issues such at outliers or nonconstant variance 

- **Plot the residuals vs. each of the predictors**
    - Can expose issues between the response and a predictor variable that didn't show in the exploratory data analysis
    - Use boxplots to plot residuals versus categorical predictor variables

--

- Residual plots should show no systematic pattern

- Plot a histogram and QQ-plot of the residuals to check Normality 

---

### Scatterplots


```r
pairs(Bsal ~ Senior + Age + Educ + Exper, data=wages)
```

&lt;img src="06-mlr_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;

---

### Residuals vs. Predicted Values


```r
wages &lt;- wages %&gt;% 
  mutate(predicted = predict.lm(model), residuals = resid(model))

ggplot(data=wages,aes(x=predicted, y=residuals)) + 
  geom_point() + 
  geom_hline(yintercept=0,color="red") +
  labs(title="Residuals vs. Predicted Values") 
```

&lt;img src="06-mlr_files/figure-html/unnamed-chunk-15-1.png" style="display: block; margin: auto;" /&gt;

---

### Residuals vs. Predictors

&lt;img src="06-mlr_files/figure-html/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /&gt;

---

### Residuals vs. Predictors 


```r
ggplot(data=wages,aes(x=Female,y=residuals)) + 
  geom_boxplot() + 
  geom_hline(yintercept=0,color="red") +
  labs(x = "Female", 
       y="Residuals")
```

&lt;img src="06-mlr_files/figure-html/unnamed-chunk-17-1.png" style="display: block; margin: auto;" /&gt;

---

### Normality of Residuals

.pull-left[
&lt;img src="06-mlr_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="06-mlr_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;
]

---

class: middle, center

## Math  Foundation

---

## Regression Model 

- The multiple linear regression model assumes 

`$$\color{blue}{y|x_1, \ldots, x_p \sim N(\beta_0 + \beta_1 x_1 + \dots + \beta_p x_p, \sigma^2)}$$`
&lt;br&gt; 

--

- For a given observation `\((x_{i1}, \ldots, x_{ip}, y_i)\)`, we can rewrite the previous statement as 

`$$\color{blue}{Y_i = \beta_0 + \beta_1 x_{i1} + \dots + \beta_p x_{ip} + \epsilon_{i} \hspace{10mm} \epsilon_i \sim N(0,\sigma^2)}$$`

---

## Estimating `\(\sigma^2\)`

- For a given observation `\((x_{i1},\ldots,x_{ip}, y_i)\)` the residual is 
`$$e_i = y_{i} - (\hat{\beta}_0 + \hat{\beta}_1 x_{i1} + \dots + \hat{\beta}_p x_{ip})$$`

--

- The &lt;font class="vocab"&gt;estimated regression variance&lt;/font&gt; is

.alert[
`$$\hat{\sigma}^2= \frac{RSS}{n-p-1} = \frac{\sum\limits_{i=1}^n[y_{i} - (\hat{\beta}_0 + \hat{\beta}_1 x_{i1} + \dots + \hat{\beta}_p x_{ip})]^2}{n-p-1}$$`

---

## Calculating `\(\hat{\sigma}^2\)`

Salary: Estimating `\(\hat{\sigma}^2\)`


```r
sigma(model)^2
```

```
## [1] 258156
```


--


```r
kable(tidy(aov(model)),format="html",digits=3)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; df &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; sumsq &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; meansq &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Senior &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3784914.70 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3784914.70 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14.661 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 17010.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 17010.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.066 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.798 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Educ &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8814046.86 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8814046.86 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 34.142 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Exper &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2095479.05 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2095479.05 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8.117 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.005 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Female &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9152264.30 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9152264.30 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35.452 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Residuals &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 87 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 22459574.96 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 258156.03 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; NA &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

## Before next class

- [Reading 04](https://www2.stat.duke.edu/courses/Spring19/sta210.001/reading/reading-04.html)
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
