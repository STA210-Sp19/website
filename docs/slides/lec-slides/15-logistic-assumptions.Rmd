---
title: "Logistic regression"
author: "Dr. Maria Tackett"
date: "03.06.19"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta210-slides.css"
    logo: img/sta210-sticker-icon.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
	fig.align = "center",
	fig.height =5,
	fig.width = 8,
	message = FALSE,
	warning = FALSE
)
```


### Announcements

- HW 05 due Mon, Mar 25 at 11:59p



---

### Packages

```{r,echo=T}
library(tidyverse)
library(knitr)
library(broom)
library(fivethirtyeight)
library(pROC) #ROC curves
library(questionr) #odds ratio function
```

---

### Review

- $Y$: binary response
  + 1: yes
  + 0: no
  
- $Mean(Y) = p$

- $Var(Y) = p(1-p)$

- **Odds of "yes"**: $\omega = \frac{p}{1-p}$

---

 

### Comparing Odds

Suppose we have two independent groups with odds $\omega_1$ and $\omega_2$

- <font class="vocab3">Odds Ratio:</font> $\phi = \frac{\omega_1}{\omega_2}$

- Use inference to assess if groups have equal odds, i.e. $\phi = 1$
  + <font class="vocab3">Hypothesis Test:</font> $$H_0: \log(\phi) = 0$$
  + <font class="vocab3">Confidence Interval:</font>
  
  $$\exp\Big\{\log(\phi) \pm z^* SE(\log(\phi))\Big\}$$

---

### Is it rude to recline your seat on a plane?


```{r}
flying <- fivethirtyeight::flying %>%
  drop_na(recline_rude, height, age) %>%
  mutate(rude = if_else(recline_rude %in% c("Somewhat", "Very"), 1, 0), 
         rude = factor(rude),
         age = factor(age, order = FALSE)) # to display in model correctly
```

- **`height`**: self-reported height in feet and inches
- **`age`**: 18-29, 30-44, 45-60, > 60
- **`rude`**: 1: yes, 0: no (Is it rude to recline your seat on a plane?)
<br><br>

Source: [*41 Percent of Fliers Think You're Rude If You Recline Your Seat*](https://fivethirtyeight.com/features/airplane-etiquette-recline-seat/)
  
---

### Opinions about flying

```{r echo=FALSE}
flying %>% 
  filter(age %in% c("18-29", "30-44")) %>%
  group_by(age, rude) %>%
  summarise(n = n()) %>%
  spread(rude, n) %>%
  kable(format="markdown")
```

**Is there a significant difference in the proportion of 18-29 year olds versus 30-44 year olds who think reclining a seat on a plane is rude?**
---

##`odds.ratio` function

- We will use the <font class="vocab">`odds.ratio`</font> function in the **questionr** package to compute odds ratios and the corresponding confidence interval

```{r}
#calculate odds ratio and 95% confidence interval
flying %>% 
  filter(age %in% c("18-29", "30-44")) %>%
  glm(rude ~ age, data = ., family = binomial) %>%
  odds.ratio(level=0.95) %>%
  kable(format="markdown", digits = 3)
```

```{r echo=F}
or <- flying %>% 
  filter(age %in% c("18-29", "30-44")) %>%
  glm(rude ~ age, data = ., family = binomial) %>%
  odds.ratio(level=0.95) %>%
  slice(2)
lb <- or$`2.5 %`
ub <- or$`97.5 %`
```


**We are 95% confident that the interval `r round(lb,3)` to `r round(ub,3)` contains the true odds ratio of 30-44 year olds versus 18-29 year olds who think reclining a seat.**

---

class: middle, center

<font class="vocab">Looking at the odds ratio is useful; however, we want to build a model to incorporate more variables that could potentially explain the odds of a flier having the opinion that reclining a seat is rude.</font>

---

### Linear model? 

- We want to use a model to predict a binary response $Y$

--

- Suppose we use a linear regression model to predict $Y$ using some explanatory variable $X$

$$Y_i = \beta_0 + \beta_1X_{i} + \epsilon_i \hspace{10mm} \epsilon_i \sim N(0,\sigma^2)$$

--

- This model assumes that $Y$ could be any continuous value; however, it can only be 0 or 1

--

- So linear regression is **not** appropriate

---

 

### Other model choices

Let $P(Y_i=1|X_i) = p_i$ and $P(Y_i=0|X_i) = 1-p_i$
<br> 
<br> 

--

Potential models for $p_i$: 
<br>

--

- **<font class="vocab">Linear:</font>** $p_i = \beta_0 + \beta_1 X_i$
  + could predict that $p_i$ is outside of $(0,1)$
--

- **<font class="vocab">Log-linear:</font>** $\log(p_i) =\beta_0 + \beta_1 X_i$
  + could predict that $p_i$ is greater than 1

---

### Logistic Regression Model 

- Suppose $P(Y_i=1|X_i) = p_i$ and $P(Y_i=0|X_i) = 1-p_i$

- The <font class="vocab3">logistic regression model </font> is

$$\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 X_i$$
<br> 


- $\log\Big(\frac{p_i}{1-p_i}\Big)$ is called the <font class="vocab3">logit</font> function


---

### Logistic Regression Model 

.alert[
$$\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 X_i$$
]
<br>

- We can calculate $p_i$ by solving the logit equation: 

$$p_i = \frac{\exp\{\beta_0 + \beta_1 X_i\}}{1 + \exp\{\beta_0 + \beta_1 X_i\}}$$

---

### Solving Logit Equation 

$$\begin{aligned}&\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 X_i\\[15pt]
\Rightarrow \hspace{8mm} &\exp\bigg\{\log\Big(\frac{p_i}{1-p_i}\Big)\bigg\} = \exp\{\beta_0 + \beta_1 X_i\}\\[15pt]
\Rightarrow \hspace{8mm} & \frac{p_i}{1-p_i} = \exp\{\beta_0 + \beta_1 X_i\} \\[15pt]
\Rightarrow \hspace{8mm}&p_i = \frac{\exp\{\beta_0 + \beta_1 X_i\}}{1+\exp\{\beta_0 + \beta_1 X_i\}}\\\end{aligned}$$

---

### Interpreting the intercept: $\beta_0$

.alert[
$$\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 X_i$$
]

--

- When $X=0$, log-odds of $Y$ are $\beta_0$
    - Won't use this interpretation in practice

- **When $X=0$, odds of $Y$ are $\exp\{\beta_0\}$**

---

### Interpreting slope coefficient $\beta_1$

.alert[
$$\log\Big(\frac{p_i}{1-p_i}\Big) = \beta_0 + \beta_1 X_i$$
]

If $X$ is a <u>quantitative</u> predictor

- As $X_i$ increases by 1 unit, log-odds of $Y$ increases by $\beta_1$

- **As $X_i$ increases by 1 unit, the odds of $Y$ multiply by a factor of $\exp\{\beta_1\}$**

--

If $X$ is a <u>categorical</u> predictor

- The difference in the log-odds between group $X$ and the baseline is $\beta_1$
- **The odds of $Y$ for group $X$ are expected to be $\exp\{\beta_1\}$ times the odds of $Y$ for the baseline group.**

---

### Inference for coefficients

- The standard error is the estimated standard deviation of the sampling distribution of $\hat{\beta}_1$

- We can calculate the $\color{blue}{C%}$ <font color="blue">confidence interval</font> based on the large-sample Normal approximations

- **CI for $\boldsymbol{\beta}_1$**: $$\hat{\beta}_1 \pm z^* SE(\hat{\beta}_1)$$

.alert[
**CI for $\exp\{\boldsymbol{\beta}_1\}$**: $$\exp\{\hat{\beta}_1 \pm z^* SE(\hat{\beta}_1)\}$$
  ]

---

### Estimating the coefficients

- Estimate coefficients using **maximum likelihood estimation**
  + covered in STA 250 and STA 360
<br> 

--


- <font class="vocab">Basic Idea: </font>
  + Find values of $\beta_0$ and $\beta_1$ that make observed values of $Y$ the most likely to have occurred
  + Use multivariable calculus and numerical methods to estimate coefficients
--

- In this class, we will use R to estimate the coefficients

---

## Logistic regression in R

- Fit a logistic model using the Use the <font class="vocab">`glm()`</font> function
    - Set <font class="vocab">`family=binomial`</font> for a binary response variable

```{r,eval=F}
my.model <- glm(Y ~ X1 + ... + XP, data = my.data,
                family = binomial)
```

- Display model with log-odds as the response
```{r eval=F}
tidy(my.model, exponentiate = FALSE) 
```

- Display model with odds as response
```{r eval=F}
tidy(my.model, exponentiate = TRUE)
```

---

### Opinions about flying

We want to use height to predict whether a flier will think reclining a seat on an airplane is rude. To do so, we will recode height so it's quantitative.

```{r}
flying <- flying %>% 
  separate(height, c("feet", "inches"), remove = FALSE) %>%
  mutate(height_in = case_when(
    height == "Under 5 ft." ~ 60, 
    TRUE ~ as.numeric(feet)*12 + as.numeric(inches)))
```

```{r}
flying %>%
  select(height, height_in) %>%
  slice(1:5)
```

---

## Reclining vs. height

Use the mean-centered `height` in the model, so the intercept will have a meaningful interpretation

```{r}
flying <- flying %>%
  mutate(heightCent = height_in - mean(height_in))
```

--

```{r}
ht_model <- glm(rude ~ heightCent, data = flying, family = binomial)
kable(tidy(ht_model, exponentiate = FALSE, conf.int = TRUE), 
      format = "markdown", digits = 3)
```

---

## Reclining vs. height

```{r echo=F}
kable(tidy(ht_model, exponentiate = FALSE, conf.int = TRUE), 
      format = "markdown", digits = 3)
```

```{r echo=F}
coef <- tidy(ht_model, exponentiate = FALSE, conf.int = TRUE)$estimate
lb <- tidy(ht_model, exponentiate = FALSE, conf.int = TRUE)$conf.low
ub <- tidy(ht_model, exponentiate = FALSE, conf.int = TRUE)$conf.high
```

- For each additional inch taller a flier is, the odds they think reclining the seat on a plane is rude are expected to multiply by a factor of `r round(exp(coef[2]),3)`), with 95% confidence interval `r round(exp(lb[2]),3)` to `r round(exp(ub[2]),3)`.

- The odds a flier of average height thinks reclining the seat on a plane is rude are `r round(exp(coef[1]),3)` to 1, with 95% confidence interval `r round(exp(lb[1]),3)` to `r round(exp(ub[1]),3)`.

--

.question[
Is `height` a significant predictor of whether a flier thinks reclining the seat is rude?
]
---

## Reclining vs. height & age
 

```{r}
ht_age_model <- glm(rude ~ heightCent + age, data = flying, 
                    family = binomial)
kable(tidy(ht_age_model, exponentiate = FALSE, conf.int = TRUE), 
      format = "markdown", digits = 3)
```

.question[
1. Interpret the coefficient of `age30-44` in the context of the data.
2. Describe the relationship between a flier's age and the odds they think reclining the seat on a plane is rude.
]

---

class: middle, center

## Predictions & Model Fit

---

## Predictions

- We are often interested in predicting if a given observation will have a "yes" response 

- To do so, we will use the logistic regression model to predict the probability of a "yes" response for the given observation. If we have one predictor variable, then...

$$p_i = \frac{\exp(\beta_0 + \beta_1 X_i)}{1 + \exp(\beta_0 + \beta_1 X_i)}$$

- We will use the predicted probabilities to classify the observation as having a "yes" or "no" response

---

### Will the passenger think I'm rude?

- Suppose you want to recline your seat on an airplane, but you first want to determine if the passenger  behind you will think you're rude. The passenger is about 6ft tall and around 35-40 years old.

--

- Predicted log-odds that this passenger thinks reclining the seat is rude: 

$$\log\bigg(\frac{\hat{p}_i}{1-\hat{p}_i}\bigg) = 0.188 + 0.013\times(72 - 67.44) - 0.782 = -0.534$$

--

- The probability this passenger thinks reclining the seat is rude: 

$$\hat{p}_i = \frac{\exp\{ -0.534\}}{1 +  \exp\{-0.534\}} = 0.3696$$

---

### Predictions in R

```{r}
x0 <- data_frame(heightCent = (72 - 67.44), age = "30-44")
```

- **Predicted log-odds**

```{r}
predict(ht_age_model, x0) 
```

- **Predicted probabilities**

```{r}
predict(ht_age_model, x0, type = "response") 
```

---

### Will the passenger think I'm rude?

```{r}
predict(ht_age_model, x0, type = "response") 
```

The probability the passenger will think you're rude is `r round(predict(ht_age_model, x0, type = "response"), 4)`.

.question[
Based on this probability, do you expect the passenger to think you're rude? Why or not why not?
]

---


### Confusion Matrix

- We can use the estimated probabilities to predict outcomes 

- *Ex.*: Establish a threshold such that $Y=1$ if predicted probability is greater than the threshold (Y=0 otherwise)

- Determine how many observations were classified correctly and incorrectly and put the results in a $2 \times 2$ table
  + This table is the <font class="vocab3">confusion matrix</font>

- If the proportion of misclassifications is high, then we conclude the model may not fit the data well

---

### Confusion Matrix

Suppose we use 0.5 as the threshold to classify responses

```{r}
threshold <- 0.5
ht_age_aug <- augment(ht_age_model, type.predict = "response")
```

```{r}
ht_age_aug %>%
  mutate(rude_predict = if_else(.fitted > threshold, "Yes", "No")) %>%
  group_by(rude, rude_predict) %>%
  summarise(n = n()) %>%
  spread(rude, n) %>%
  kable(format="markdown")
```

---

## Confusion matrix

```{r echo=F}
ht_age_aug %>%
  mutate(rude_predict = if_else(.fitted > threshold, "Yes", "No")) %>%
  group_by(rude, rude_predict) %>%
  summarise(n = n()) %>%
  spread(rude, n) %>%
  kable(format="markdown")
```
<br><br>

.question[ 
What proportion of observations were misclassified?]

---

### Sensitivity & Specificity

- <font class="vocab3">Sensitivity: </font>Proportion of observations with $Y=1$ that have predicted probability above a specified threshold
  + Called true positive rate

- <font class="vocab3">Specificity: </font>Proportion of observations with $Y=0$ that have predicted probability below a specified threshold
  + (1 - specificity) called false positive rate

- What we want: 
  + High sensitivity
  + Low values of 1-specificity

---

class: regular 

### ROC Curve

- <font class="vocab3">Receive Operating Characteristic (ROC) curve </font>: 
  + *X-axis*: $1 - \text{ specificity}$
  + *Y-axis*: $\text{ Sensitivity}$ 
  
- Evaluated with a lot of different values for the threshold

- Logistic model fits well if the area under the curve (AUC) is close to 1

- ROC in R
    - Use the <font class="vocab">`roc`</font> function in the `pROC` to calculate AUC
    - Use <font class="vocab">`geom_roc`</font> layer in ggplot to plot the ROC curve

---

### Visualize ROC curve

```{r}
library(plotROC) #extension of ggplot2
ggplot(ht_age_aug, aes(d = as.numeric(rude), m = .fitted)) + 
  geom_roc(n.cuts = 0) + 
  geom_abline(intercept = 0)
```



---

## Area under curve

```{r}
library(pROC)
roc(ht_age_aug$rude,ht_age_aug$.fitted)$auc
```

```{r echo=F}
library(plotROC) #extension of ggplot2
ggplot(ht_age_aug, aes(d = as.numeric(rude), m = .fitted)) + 
  geom_roc(n.cuts = 0) + 
  geom_abline(intercept = 0)
```


---

---
title: "Logistic Regression"
subtitle: ""
author: "Dr. Tackett"
date: "11.08.2018"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    lib_dir: libs
    css: 
      - sta210_slides.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{rinclude=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
	fig.align = "center",
	fig.height =5,
	fig.width = 8,
	message = FALSE,
	warning = FALSE,
	echo=TRUE
)
```



class: regular

### Announcements


- HW 6 due today

- Lab 8 due Sunday, 11/11

- Project Proposal due Tuesday, 11/13
  + Example posters in office

- HW 7 due Thursday, 11/15

---

class: regular 

### Packages
```{r,echo=T}
library(knitr)
library(broom)
library(dplyr)
library(tibble)
library(ggplot2)
library(pROC) #ROC curves
#library(arm) #binned residuals
library(NHANES) #subset of NHANES dataset
library(questionr) #odds ratio function
```

---

class: regular 

### Review

- $Y$: binary response
  + 1: yes
  + 0: no
  
- $Mean(Y) = \pi$

- $Var(Y) = \pi(1-\pi)$

- **Odds of "yes"**: $\omega = \frac{\pi}{1-\pi}$

---

class: regular 

### Comparing Odds

Suppose we have two independent groups with odds $\omega_1$ and $\omega_2$

- <font class="vocab3">Odds Ratio:</font> $\phi = \frac{\omega_1}{\omega_2}$

- Use inference to assess if groups have equal odds, i.e. $\phi = 1$
  + <font class="vocab3">Hypothesis Test:</font> $$H_0: \log(\phi) = 0$$
  + <font class="vocab3">Confidence Interval:</font>
  
  $$\exp\Big\{\log(\phi) \pm z^* SE(\log(\phi))\Big\}$$

---

class: regular 

### NHANES Data

- <a  href="https://www.cdc.gov/nchs/nhanes/index.htm" target="_blank">National Health and Nutrition Examination Survey</a> is conducted by the National Center for Health Statistics (NCHS) 

- The goal is to *"assess the health and nutritional status of adults and children in the United States"*

- This survey includes an interview and a physical examination

---

class: regular 

### NHANES Data

- We will use the data from the <font class="vocab">`NHANES`</font> R package

- Contains 75 variables for the 2009 - 2010 and 2011 - 2012 sample years

- The data in this package is modified for educational purposes and should **not** be used for research

- Original data can be obtained from the <a href="https://www.cdc.gov/nchs/data_access/index.htm" target="_blank">NCHS website</a> for research purposes

- Type <font class="vocab">`?NHANES`</font> in console to see list of variables and definitions

---

class: regular 

### NHANES: Physical Activity & Sleep

- Do people who do regular physical activity have lower odds of sleep problems than those who do not do regular physical activity?

- We will analyze the following variables: 
  + <font class="vocab">`PhysActive`: </font>Participant does moderate to vigorous-intensity sports, fitness or recreational activities
  
  + <font class="vocab">`SleepTrouble`: </font>Participant has told doctor or other health professional they had trouble sleeping
  
---

class: regular 

### NHANES: Physical Activity & Sleep

```{r}
# Filter data to only include adults with all data for pulse 
set.seed(1234)
nhanes <- NHANES %>% filter(Age > 18, !is.na(Pulse)) %>% 
  sample_n(500)
nhanes %>% select(Age,Gender,PhysActive,SleepTrouble) %>% glimpse()
```
---

class: regular 

### NHANES: Physical Activity & Sleep

```{r}
#get counts for each combination of PhysActive and SleepTrouble
table <- nhanes %>% group_by(PhysActive,SleepTrouble) %>% summarise(n=n())
kable(table,format="html")
```

```{r,echo=F}
#Group 1: PhysActive=Yes, Group 2: PhysActive=No
#proportion with sleep trouble
n1 <- table[3,3] + table[4,3]
n2 <- table[1,3] + table[2,3]
p1 <- table[4,3]/n1
p2 <- table[2,3]/n2
pc <- (table[2,3]+table[4,3])/(n1+n2)
```

```{r,echo=F}
#odds with sleep trouble
omega1 <- p1/(1-p1)
omega2 <- p2/(1-p2)
phi <- omega1/omega2
```

```{r,echo=F}
# SE
se = sqrt((n1*p1*(1-p1))^(-1) + (n2*p2*(1-p2))^(-1))
se0 = sqrt((n1*pc*(1-pc))^(-1) + (n2*pc*(1-pc))^(-1))
```

---

class: regular 

### NHANES: Physical Activity & Sleep

- **Group 1: PhysActive="Yes", Group 2: PhysActive="No"**
  + $\hat{\omega}_1$: `r round(omega1,4)`
  + $\hat{\omega}_2$: `r round(omega2,4)`
  + $\hat{\phi}$: `r round(phi,4)`
  + $SE(\log(\hat{\phi}))$ = `r round(se,4)`
  + $SE_0(\log(\hat{\phi}))$ = `r round(se0,4)`


- Is there evidence that people who do regular physical activity have lower odds of sleep problems than those who do not do regular physical activity?
- Calculate a 95% confidence interval for the odds ratio.

---

class: regular 

### NHANES: Physical Activity & Sleep

- R has a functions to calculate the odds ratio 

- <font class="vocab">`odds.ratio()`</font> function in the `questionr` package is shown below

```{r}
#calculate odds ratio and 95% confidence interval
model <- glm(SleepTrouble ~ PhysActive, family=binomial, data=nhanes)
or <- odds.ratio(model,level=0.95)
kable(or,format="html",digits=3)
```

---

class: middle, center

<font class="vocab3">We want to build a model to incorporate more variables that could potentially explain the odds of having sleep problems.</font>

---


class: regular 

### Linear model? 

- We want to use a model to predict a binary response $Y$

--

- Suppose we use a linear regression model to predict $Y$ using some explanatory variable $X$

$$Y_i = \beta_0 + \beta_1X_{i} + \epsilon_i \hspace{10mm} \epsilon_i \sim N(0,\sigma^2)$$

--

- This model assumes that $Y$ could be any continuous value; however, it can only be 0 or 1

--

- So linear regression is not appropriate

---

class: regular 

### Other model choices

Let $P(Y_i=1|X_i) = \pi_i$ and $P(Y_i=0|X_i) = 1-\pi_i$
<br> 
<br> 

--

Potential models for $\pi_i$: 
<br>

--

- **<font class="vocab">Linear:</font>** $\pi_i = \beta_0 + \beta_1 X_i$
  + $\pi_i$ possibly outside of $(0,1)$
--

- **<font class="vocab">Log-linear:</font>** $\log(\pi_i) =\beta_0 + \beta_1 X_i$
  + $\pi_i$ possibly greater than 1

---

class: regular 

### Logistic Regression Model 

- Suppose $P(Y_i=1|X_i) = \pi_i$ and $P(Y_i=0|X_i) = 1-\pi_i$

- The <font class="vocab3">logistic regression model </font> is

$$\log\Big(\frac{\pi_i}{1-\pi_i}\Big) = \beta_0 + \beta_1 X_i$$
<br> 


- $\log\Big(\frac{\pi_i}{1-\pi_i}\Big)$ is called the <font class="vocab3">logit</font> function


---

class: regular 

### Logistic Regression Model 

$$\log\Big(\frac{\pi_i}{1-\pi_i}\Big) = \beta_0 + \beta_1 X_i$$
<br> 
<br> 

- We can calculate $\pi_i$ by solving the logit equation: 

$$\pi_i = \frac{\exp\{\beta_0 + \beta_1 X_i\}}{1 + \exp\{\beta_0 + \beta_1 X_i\}}$$

---

class: regular 

### Solving Logit Equation 

$$\begin{aligned}&\log\Big(\frac{\pi_i}{1-\pi_i}\Big) = \beta_0 + \beta_1 X_i\\
\Rightarrow \hspace{8mm} &\exp\bigg\{\log\Big(\frac{\pi_i}{1-\pi_i}\Big)\bigg\} = \exp\{\beta_0 + \beta_1 X_i\}\\
\Rightarrow \hspace{8mm} & \frac{\pi_i}{1-\pi_i} = \exp\{\beta_0 + \beta_1 X_i\} \\
\Rightarrow \hspace{8mm}&\pi_i = \frac{\exp\{\beta_0 + \beta_1 X_i\}}{1+\exp\{\beta_0 + \beta_1 X_i\}}\\\end{aligned}$$

---

class: regular 

### Interpreting Model Coefficients

$$\log\Big(\frac{\pi_i}{1-\pi_i}\Big) = \beta_0 + \beta_1 X_i$$

--

- <font class="vocab">Slope, $\beta_1$: </font>
  + As $X_i$ increases by 1 unit, log-odds of $Y$ increases by $\beta_1$
  + As $X_i$ increases by 1 unit, the odds of $Y$ multiply by a factor of $\exp\{\beta_1\}$

---

class: regular 

### Interpreting Model Coefficients

$$\log\Big(\frac{\pi_i}{1-\pi_i}\Big) = \beta_0 + \beta_1 X_i$$

--

- <font class="vocab">Intercept, $\beta_0$: </font>
  + When $X=0$, log-odds of $Y$ are $\beta_0$
  + When $X=0$, odds of $Y$ are $\exp\{\beta_0\}$
  + If we mean-center $X$, then we can interpret the intercept in terms of the mean of $X$
--

- Can interpret results by graphing predicted $\pi$ for values of $X$

---

class: regular 

### Estimating the Coefficients

- Estimate coefficients using *maximum likelihood estimation*
  + covered in STA 250 and STA 360
--

- <font class="vocab">Basic Idea: </font>
  + Find values of $\beta_0$ and $\beta_1$ that make observed values of $Y$ the most likely to have occurred
  + Use multivariable calculus and numerical methods to estimate coefficients
--

- We will use R to estimate the coefficients

---

class: regular 

### Inference for Coefficients

- <font class="vocab3">standard error, $SE(\hat{\beta}_1)$: </font>estimated standard deviation of the sampling distribution of $\hat{\beta}_1$

- We can calculate the $\color{blue}{100(1-\alpha)\%}$ <font color="blue">confidence interval</font> based on the large-sample Normal approximations
  + **CI for $\boldsymbol{\beta}_1$**: $$\hat{\beta}_1 \pm z^* SE(\beta_1)$$
  + **CI for $\exp\{\boldsymbol{\beta}_1\}$**: $$\exp\{\hat{\beta}_1 \pm z^* SE(\beta_1)\}$$

---

class: regular 

### Logistic Regression in R

- Use the <font class="vocab">`glm()`</font> function in R 

- Set <font class="vocab">`family=binomial`</font>

```{r,eval=F}
my.model <- glm(Y ~ X, family=binomial,data=my.data)
```

---

class: regular 

### NHANES: Pulse Rate & Sleep

- **Can pulse rate be used to distinguish the odds of an adult having trouble sleeping?**

- <font class="vocab">`Pulse`</font>: 60 second pulse rate


```{r}
#caluclate logistic model using mean-centered Pulse
nhanes <- nhanes %>% mutate(pulse.cent = Pulse - mean(Pulse))
log.odds <- glm(SleepTrouble ~ pulse.cent, family=binomial,data=nhanes)
kable(tidy(log.odds),format="html",digits=3)
```

---

class: regular 

### NHANES: Pulse Rate & Sleep
```{r,echo=F}
#caluclate logistic model using mean-centered Pulse
kable(tidy(log.odds),format="html",digits=3)
```

```{r,include=F,echo=F}
interval <- confint_tidy(log.odds)
```


- <font class="vocab">Slope: </font> As pulse rate increases by 1 beat per minute, the odds of having sleep trouble are expected to multiply by a factor of `r round(exp(log.odds$coefficients[2]),2)`, with 95% confidence interval `r round(exp(interval[2,1]),3)` to `r round(exp(interval[2,2]),3)`

--

- <font class="vocab">Intercept: </font> A person with an average pulse (`r round(mean(nhanes$Pulse),3)` beats per minute) is expected to have `r round(exp(log.odds$coefficients[1]),2)` to 1 odds of having sleep trouble, with 95% confidence interval `r round(exp(interval[1,1]),3)` to `r round(exp(interval[1,2]),3)`

---

class: regular 

### NHANES: Computers & Sleep

- <font class="vocab">`CompHrsDay`: </font> Number of hours per day on average participant used a computer or gaming device over the last 30 days. 
  + 0_hrs
  + 0_to_1_hr
  + 1_hr
  + 2_hr
  + 3_hr
  + 4_hr
  + More_4_hr
- <font class="vocab">`Age`: </font> Age at time of screening (in years). Participants 80 or older were recorded as 80.

---

class: regular 

### NHANES: Computers & Sleep

```{r,echo=F}
#use mean-centered age
nhanes <- nhanes %>% mutate(age.mean = Age - mean(Age))
log.computer <- glm(SleepTrouble ~ CompHrsDay + Age,family=binomial,data=nhanes)
kable(tidy(log.computer),format="html",digits=3)
```


- Describe the relationship between the amount of time spent on a computer and the odds of having trouble sleeping after adjusting for age.

---

class: regular

### Assumptions & Model Fit

- <font class="vocab">Assumptions</font>
  + Independence of residuals
  + Log-odds has linear relationship with explanatory variables
  + No significant impacts due to influential points or multicollinearity (when there are multiple explanatory variables)
--

- Not effective to examine the residuals
  + Residual positive when $Y=1$ and negative when $Y=0$
  + Constant variance not an assumption of logistic regression
  + Normality of residuals not an assumption of logistic regression

---

class: regular

### Assumptions & Model Fit

- <font class="vocab">Check Assumptions</font>
  + Plot of binned residuals vs. predicted values
  + Plot of binned residuals vs. numeric explanatory variables
  + Leverage, Cook's distance, and multicollinearity (if more than one explanatory variable)
--

- <font class="vocab">Check Model Fit</font>
  + Examine ROC curve
  + Examine confusion matrix

---

class: regular

### Binned Residuals

To examine binned residuals...

- Calculate raw residuals
- Order observations either by the values of the predicted probabilities or by the numeric explanatory variable itself
- Use the ordered data to create *g* bins of approximately equal size
  + Default value: $g = \sqrt{n}$
- Calculate average residual value in each bin
- Plot average residuals vs. average predicted probability (or average explanatory variable)

--

Can use the <font class="vocab">`arm`</font> package in R

---

class: regular

### Binned Residuals

- Look for patterns

- Nonlinear trend may be indication that squared term or log transformation of explanatory variable required

- If bins have average residuals with large magnitude
  + Look at averages of other explanatory variables across bins
  + Interaction may be required if large residuals correspond to certain combinations of explanatory variables
  
---

class: regular 

### Raw Residuals: Pulse & Sleep

```{r}
nhanes <- nhanes %>%
  mutate(Residuals = residuals.glm(log.odds,type="response"), 
         Predicted = predict.glm(log.odds,type="response"))
```

```{r,echo=F}
#plot raw residuals vs. predicted
ggplot(data=nhanes, aes(x=Predicted,y=Residuals)) + 
  geom_point() + geom_hline(yintercept=0,color="red")+
  labs(title="Raw Residuals vs. Predicted")+
  theme(plot.title=element_text(hjust=0.5))
```
---

class: regular 

### Binned Residuals - Pulse & Sleep
```{r}
library(arm)
binnedplot(x=nhanes$Predicted,y=nhanes$Residuals,xlab="Predicted Probabilities")
```

---

class: regular 

### Binned Residuals - Pulse & Sleep
```{r}
library(arm)
binnedplot(x=nhanes$Pulse,y=nhanes$Residuals,xlab="Pulse")
```






